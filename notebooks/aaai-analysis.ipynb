{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "219d9cbc-7f70-4826-b84d-9268c1e5cca6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# from jupyter_client import kernelspec\n",
    "# spec = kernelspec.get_kernel_spec(kernel_name=\"PyTorch-2.0.1\")\n",
    "# print(spec.resource_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d9b85cd-9cc7-43cd-a1bb-32d34d87cc7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_run_files(root=\"/orange/ufdatastudios/alexwebber/mixteclabeling/out/runs\", model='vit_l_16'):\n",
    "    # return [x for x in Path(root).glob(\"**/*.0\") if x.suffix == \".0\"]\n",
    "    return [x for x in Path(root).glob(\"**/version_0/*.0\") if x.suffix == \".0\" and model in str(x)]\n",
    "\n",
    "def get_scalar_run_tensorboard(tag, filepath:str):\n",
    "    values,steps = [],[]\n",
    "    for e in tf.compat.v1.train.summary_iterator(filepath):\n",
    "        if len(e.summary.value)>0: #Skip first empty element\n",
    "            if e.summary.value[0].tag==tag:\n",
    "                tensor = e.summary.value[0]\n",
    "                value, step = (e.summary.value[0].simple_value, e.step)\n",
    "                values.append(value)\n",
    "                steps.append(step)\n",
    "    return values, steps\n",
    "\n",
    "def return_the_substring(text, keylist):\n",
    "    for key in keylist:\n",
    "        if key in text:\n",
    "            return key\n",
    "    return None\n",
    "\n",
    "def round_it(listofvalues, by=5):\n",
    "    \"\"\"Rounds each value in the list of values to the closest by.\"\"\"\n",
    "    return map(lambda x: x-x%by, listofvalues)\n",
    "\n",
    "lr_pattern = re.compile(r'lr([0-9]*\\.?[0-9]+)--')\n",
    "def get_learningrates(files):\n",
    "    \"\"\"Extract the learning rate from the file name.\n",
    "    \n",
    "        ex: \"...vit_l_16--lr0.00025--bs128...:\n",
    "    \"\"\"\n",
    "    for file in files:\n",
    "        match = lr_pattern.search(str(file))\n",
    "        if match:\n",
    "            yield match.group(1)\n",
    "\n",
    "    \n",
    "list_of_tags = [ 'train_acc_epoch',\n",
    " 'train_f1_epoch',\n",
    " 'train_prec_epoch',\n",
    " 'train_rec_epoch',\n",
    " 'val_acc_epoch',\n",
    " 'val_f1_epoch',\n",
    " 'val_prec_epoch',\n",
    " 'val_rec_epoch']\n",
    "\n",
    "# list_of_tags = [\"train_f1_epoch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f82e362a-ce0b-44dd-916c-cee7c268b6f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# f = '/orange/ufdatastudios/alexwebber/mixteclabeling/out/runs/2023-09-22--vit_l_16--lr0.01--bs128--transformsRandomHorizontalFlip_RandomVerticalFlip/version_0/events.out.tfevents.1695365914.c0800a-s23.ufhpc.1607097.0'\n",
    "# set([ e.summary.value[0].tag for e in tf.compat.v1.train.summary_iterator(f) if e.summary.value ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e5f24a1-2743-4272-9ad2-981219e0096b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0.0001', '0.00025', '0.0005'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = get_run_files()\n",
    "# list(set(filter(lr_pattern.search, map(str, files))))\n",
    "# list(map(lambda x: x.absolute, files))\n",
    "# str(files[0].absolute())\n",
    "set(get_learningrates(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "128a1c2c-841c-49c2-be77-0f89edf07100",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_plot(model='vit_l_16'):\n",
    "    files = get_run_files(model=model)\n",
    "    print(f\"total files: {len(files)}\")\n",
    "    \n",
    "    lrs = list(get_learningrates(files)) # learning rates of each file\n",
    "    print(f\"total lrs: {len(lrs)}\")\n",
    "\n",
    "    tags = list_of_tags\n",
    "    print(f\"{tags=}\")\n",
    "    \n",
    "    # Grab tags from the tensorboard log files\n",
    "    for tag in tags:\n",
    "        lr = {}\n",
    "        for rate in lrs:\n",
    "            lr[rate] = { \"steps\": [], \"values\": [] }\n",
    "                \n",
    "        # print(f\"total all: {len( list(zip(map(str,files), lrs)) )}\")\n",
    "        for file in map(str,files):\n",
    "            values, steps = get_scalar_run_tensorboard(tag, file)\n",
    "            steps = round_it(steps, 50)\n",
    "            \n",
    "            # Extract the file learning rage\n",
    "            filelr = str(list(get_learningrates([file]))[0])\n",
    "\n",
    "            lr[filelr][\"steps\"].extend(steps)\n",
    "            lr[filelr][\"values\"].extend(values)\n",
    "        \n",
    "        # Get mean and stddev for each step in lr2\n",
    "        lr2 = {}\n",
    "        for i, (k,data) in enumerate(lr.items()):\n",
    "            d = defaultdict(list) # values list\n",
    "            for (step, value) in zip(data[\"steps\"], data[\"values\"]):\n",
    "                d[step].append(value)\n",
    "            # Get avg and stddev of each step\n",
    "            d2 = {}\n",
    "            for (step, vals) in d.items():\n",
    "                d2[step] = {\"avg\": np.average(vals), \"std\": np.std(vals) }\n",
    "            lr2[k] = d2\n",
    "        \n",
    "        import pprint \n",
    "        # pprint.pprint(lr2)\n",
    "        \n",
    "        plt.figure()\n",
    "\n",
    "        handlekeys = [] # Used for legend\n",
    "        for key, data in lr2.items():\n",
    "            # e.g. key = \"0.01\", data = {step: { avg, std } }\n",
    "            # print(f\"key: {key}\") \n",
    "\n",
    "            datakeys = list(data.keys())\n",
    "            # datakeys = preprocessing.minmax_scale([list(data.keys())], axis=1)\n",
    "            normalizedsteps = preprocessing.minmax_scale([datakeys], axis=1)[0]\n",
    "            \n",
    "            averages = list(map(lambda x: x[\"avg\"], list(data.values())))\n",
    "            upperbound = list(map(lambda x: x[\"avg\"] + x[\"std\"], list(data.values())))\n",
    "            lowerbound = list(map(lambda x: x[\"avg\"] - x[\"std\"], list(data.values())))\n",
    "\n",
    "            # handle, = plt.plot(datakeys, averages, linewidth=1, label=key)\n",
    "            handle, = plt.plot(normalizedsteps, averages, linewidth=1, label=key)    \n",
    "        \n",
    "            handlekeys.append(handle)\n",
    "            # plt.fill_between(datakeys, upperbound, lowerbound, alpha=.5, linewidth=0)   \n",
    "            plt.fill_between(normalizedsteps, upperbound, lowerbound, alpha=.5, linewidth=0)   \n",
    "\n",
    "        # plt.legend(lr.keys(), loc=\"lower right\")\n",
    "        plt.ylim([0, 1.19])\n",
    "        plt.grid()\n",
    "        plt.legend(handles=handlekeys, loc=\"lower right\")\n",
    "        # plt.xlabel(\"steps\")\n",
    "        plt.ylabel(tag)\n",
    "\n",
    "        #print(f'{sorted(Counter(lr[\"0.01\"][\"steps\"]).items())}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429edd08-6ed7-4575-9a51-b7d1569dc386",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total files: 48\n",
      "total lrs: 48\n",
      "tags=['train_acc_epoch', 'train_f1_epoch', 'train_prec_epoch', 'train_rec_epoch', 'val_acc_epoch', 'val_f1_epoch', 'val_prec_epoch', 'val_rec_epoch']\n"
     ]
    }
   ],
   "source": [
    "# NotebookApp.iopub_data_rate_limit=10000000.0\n",
    "generate_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f415bf1-f2a9-4073-a267-fcbe82f2a83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_plot(model=\"vgg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19087d44-ba9a-4b5e-9776-13753906ca08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# List all the files\n",
    "get_run_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603c3bb2-9ec3-4092-8d3b-acbdf704f768",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-2.0.1",
   "language": "python",
   "name": "pytorch-2.0.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
